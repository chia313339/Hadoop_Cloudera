[training@localhost ~]$ pyspark
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 1.3.0
      /_/

Using Python version 2.7.8 (default, Sep 16 2015 11:31:11)
SparkContext available as sc, HiveContext available as sqlCtx.

In [1]: mydata = sc.textFile("purplecow.txt")                                  

In [2]: myrdd1 = mydata.map(lambda s: s.upper())

In [4]: myrdd2 = myrdd1.filter(lambda s:s.startswith('I'))

In [5]: myrdd2.count()
16/02/18 15:35:51 INFO HadoopRDD: Input split: hdfs://localhost:8020/user/training/purplecow.txt:55+56
16/02/18 15:35:51 INFO HadoopRDD: Input split: hdfs://localhost:8020/user/training/purplecow.txt:0+55
Out[5]: 3

In [6]: myrdd2.count()
16/02/18 15:36:05 INFO HadoopRDD: Input split: hdfs://localhost:8020/user/training/purplecow.txt:55+56
16/02/18 15:36:05 INFO HadoopRDD: Input split: hdfs://localhost:8020/user/training/purplecow.txt:0+55
Out[6]: 3

In [7]: myrdd1.persist()
Out[7]: PythonRDD[4] at RDD at PythonRDD.scala:42

In [10]: myrdd2 = myrdd1.filter(lambda s:s.startswith('I'))

In [11]: myrdd2.count()
16/02/18 15:37:18 INFO HadoopRDD: Input split: hdfs://localhost:8020/user/training/purplecow.txt:55+56
16/02/18 15:37:18 INFO HadoopRDD: Input split: hdfs://localhost:8020/user/training/purplecow.txt:0+55
Out[11]: 3

In [12]: myrdd2.count()
16/02/18 15:37:24 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.5 KB, free 265.1 MB)
16/02/18 15:37:24 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.0 KB, free 265.1 MB)
16/02/18 15:37:24 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:57350 (size: 4.0 KB, free: 265.4 MB)
16/02/18 15:37:24 INFO BlockManagerMaster: Updated info of block broadcast_6_piece0
16/02/18 15:37:24 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:839
16/02/18 15:37:24 INFO BlockManager: Found block rdd_4_0 locally
16/02/18 15:37:24 INFO BlockManager: Found block rdd_4_1 locally

Out[12]: 3

In [13]: myrdd3 = myrdd1.filter(lambda s:s.startswith('B'))

In [14]: myrdd3.count()
16/02/18 15:39:51 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 6.5 KB, free 265.1 MB)
16/02/18 15:39:51 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
16/02/18 15:39:51 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:57350 (size: 3.9 KB, free: 265.4 MB)
16/02/18 15:39:51 INFO BlockManagerMaster: Updated info of block broadcast_7_piece0
16/02/18 15:39:51 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:839
16/02/18 15:39:51 INFO BlockManager: Found block rdd_4_0 locally
16/02/18 15:39:51 INFO BlockManager: Found block rdd_4_1 locally
Out[14]: 1

In [15]: myrdd1.unpersist()
16/02/18 15:46:47 INFO PythonRDD: Removing RDD 4 from persistence list
16/02/18 15:46:47 INFO BlockManager: Removing RDD 4
16/02/18 15:46:47 INFO BlockManager: Removing block rdd_4_0
16/02/18 15:46:47 INFO MemoryStore: Block rdd_4_0 of size 171 dropped from memory (free 277990400)
16/02/18 15:46:47 INFO BlockManager: Removing block rdd_4_1
16/02/18 15:46:47 INFO MemoryStore: Block rdd_4_1 of size 91 dropped from memory (free 277990491)
Out[15]: PythonRDD[4] at RDD at PythonRDD.scala:42

In [16]: myrdd3.count()
16/02/18 15:47:48 INFO HadoopRDD: Input split: hdfs://localhost:8020/user/training/purplecow.txt:0+55
16/02/18 15:47:48 INFO HadoopRDD: Input split: hdfs://localhost:8020/user/training/purplecow.txt:55+56
Out[16]: 1



